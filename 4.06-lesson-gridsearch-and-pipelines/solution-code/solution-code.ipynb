{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Introduction to Gridsearching & Hyperparameters\n",
    "\n",
    "_Authors: Kiefer Katovich (SF), David Yerrington (SF), Matt Brems_\n",
    "\n",
    "---\n",
    "\n",
    "![](https://snag.gy/aYcCt2.jpg)\n",
    "\n",
    "### Learning Objectives\n",
    "- Describe what the terms gridsearch and hyperparameter mean.\n",
    "- Build a gridsearching procedure from scratch.\n",
    "- Apply sklearn's `GridSearchCV` object.\n",
    "- Use and evaluate attributes of the gridsearch object.\n",
    "- Describe the pitfalls of searching large hyperparameter spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data.\n",
    "data = pd.read_csv('../datasets/UNdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>lifeMale</th>\n",
       "      <th>lifeFemale</th>\n",
       "      <th>infantMortality</th>\n",
       "      <th>GDPperCapita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>154</td>\n",
       "      <td>2848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Europe</td>\n",
       "      <td>68.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>32</td>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Africa</td>\n",
       "      <td>67.5</td>\n",
       "      <td>70.3</td>\n",
       "      <td>44</td>\n",
       "      <td>1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>Africa</td>\n",
       "      <td>44.9</td>\n",
       "      <td>48.1</td>\n",
       "      <td>124</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>America</td>\n",
       "      <td>69.6</td>\n",
       "      <td>76.8</td>\n",
       "      <td>22</td>\n",
       "      <td>8055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country   region  lifeMale  lifeFemale  infantMortality  GDPperCapita\n",
       "0  Afghanistan     Asia      45.0        46.0              154          2848\n",
       "1      Albania   Europe      68.0        74.0               32           863\n",
       "2      Algeria   Africa      67.5        70.3               44          1531\n",
       "3       Angola   Africa      44.9        48.1              124           355\n",
       "4    Argentina  America      69.6        76.8               22          8055"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine first five rows.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## United Nations Data\n",
    "\n",
    "- `country`: the name of the nation\n",
    "- `region`: the region of the world (Africa, America, Asia, Europe, Oceania)\n",
    "- `lifeMale`: the life expectancy of males\n",
    "- `lifeFemale`: the life expectancy of females\n",
    "- `infantMortality`: the infant mortality rate (generally reported per 1,000 live births)\n",
    "- `GDPperCapita`: the Gross Domestic Product per person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Africa     53\n",
       "Asia       46\n",
       "Europe     40\n",
       "America    35\n",
       "Oceania    14\n",
       "Name: region, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine distribution of region.\n",
    "data['region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many rows do we have?\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country            0\n",
       "region             0\n",
       "lifeMale           0\n",
       "lifeFemale         0\n",
       "infantMortality    0\n",
       "GDPperCapita       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values.\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set country to be the index.\n",
    "data.set_index('country', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>lifeMale</th>\n",
       "      <th>lifeFemale</th>\n",
       "      <th>infantMortality</th>\n",
       "      <th>GDPperCapita</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>Asia</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>154</td>\n",
       "      <td>2848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>Europe</td>\n",
       "      <td>68.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>32</td>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>Africa</td>\n",
       "      <td>67.5</td>\n",
       "      <td>70.3</td>\n",
       "      <td>44</td>\n",
       "      <td>1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>Africa</td>\n",
       "      <td>44.9</td>\n",
       "      <td>48.1</td>\n",
       "      <td>124</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>America</td>\n",
       "      <td>69.6</td>\n",
       "      <td>76.8</td>\n",
       "      <td>22</td>\n",
       "      <td>8055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              region  lifeMale  lifeFemale  infantMortality  GDPperCapita\n",
       "country                                                                  \n",
       "Afghanistan     Asia      45.0        46.0              154          2848\n",
       "Albania       Europe      68.0        74.0               32           863\n",
       "Algeria       Africa      67.5        70.3               44          1531\n",
       "Angola        Africa      44.9        48.1              124           355\n",
       "Argentina    America      69.6        76.8               22          8055"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy region.\n",
    "data = pd.get_dummies(data, columns=['region'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What is our reference category for this dummy variable?</summary>\n",
    "\n",
    "- Africa!\n",
    "- There is no dummy variable for Africa in our data, meaning that all dummy variables would be interpreted **relative to Africa**.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create $Y$ variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column with 1 if the female life expectancy is greater\n",
    "# than the male life expectancy.\n",
    "data['females_are_strong_as_hell'] = (data['lifeFemale'] > data['lifeMale']).astype(int)\n",
    "\n",
    "# The column name is a reference to the \n",
    "# Netflix series \"The Unbreakable Kimmy Schmidt.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.989362\n",
       "0    0.010638\n",
       "Name: females_are_strong_as_hell, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What should we check next?\n",
    "data['females_are_strong_as_hell'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Do you have any concerns about the above?</summary>\n",
    "    \n",
    "- Our classes are severely unbalanced.\n",
    "- We should check out our tools for handling unbalanced classes. (e.g. moving our classification threshold, implement stratified k-fold cross validation)\n",
    "- Given the relatively low sample size and the small number of the observations in the minority category here, it is unlikely that our model would be able to predict that a nation has a higher male life expectancy.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.569149\n",
       "1    0.430851\n",
       "Name: females_are_strong_as_hell, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a column with 1 if the female life expectancy is 5\n",
    "# or more years longer than the male life expectancy.\n",
    "data['females_are_strong_as_hell'] = (data['lifeFemale'] >= (data['lifeMale'] + 5)).astype(int)\n",
    "\n",
    "# Check the thing we need to check!\n",
    "data['females_are_strong_as_hell'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We are interested in predicting whether or not the female life expectancy of a nation is at least five years great than the male life expectancy.** This is a classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up X and y.\n",
    "X = data.drop(columns='females_are_strong_as_hell')\n",
    "y = data['females_are_strong_as_hell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lifeMale</th>\n",
       "      <th>lifeFemale</th>\n",
       "      <th>infantMortality</th>\n",
       "      <th>GDPperCapita</th>\n",
       "      <th>region_America</th>\n",
       "      <th>region_Asia</th>\n",
       "      <th>region_Europe</th>\n",
       "      <th>region_Oceania</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>154</td>\n",
       "      <td>2848</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>68.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>32</td>\n",
       "      <td>863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>67.5</td>\n",
       "      <td>70.3</td>\n",
       "      <td>44</td>\n",
       "      <td>1531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>44.9</td>\n",
       "      <td>48.1</td>\n",
       "      <td>124</td>\n",
       "      <td>355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>69.6</td>\n",
       "      <td>76.8</td>\n",
       "      <td>22</td>\n",
       "      <td>8055</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             lifeMale  lifeFemale  infantMortality  GDPperCapita  \\\n",
       "country                                                            \n",
       "Afghanistan      45.0        46.0              154          2848   \n",
       "Albania          68.0        74.0               32           863   \n",
       "Algeria          67.5        70.3               44          1531   \n",
       "Angola           44.9        48.1              124           355   \n",
       "Argentina        69.6        76.8               22          8055   \n",
       "\n",
       "             region_America  region_Asia  region_Europe  region_Oceania  \n",
       "country                                                                  \n",
       "Afghanistan               0            1              0               0  \n",
       "Albania                   0            0              1               0  \n",
       "Algeria                   0            0              0               0  \n",
       "Angola                    0            0              0               0  \n",
       "Argentina                 1            0              0               0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our data into training and testing sets.\n",
    "# I've picked to have a test size of 33% because I want to \n",
    "# make sure that I have enough data in the test set to\n",
    "# meaningfully evaluate my model.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.33,\n",
    "                                                    random_state = 42,\n",
    "                                                    stratify = y) # Note the stratify parameter here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.568\n",
      "1    0.432\n",
      "Name: females_are_strong_as_hell, dtype: float64\n",
      "0    0.571429\n",
      "1    0.428571\n",
      "Name: females_are_strong_as_hell, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# What did stratify = y do?\n",
    "\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Before we fit a k-Nearest Neighbors model, what do we need to do? Why?</summary>\n",
    "    \n",
    "- Standardize our data!\n",
    "- If we *don't* standardize our data, then features that have larger spreads (e.g. higher ranges or higher standard deviations) will have a disproportionate influence on our model.\n",
    "- If all of your variables are already on the same scale, then scaling is not necessary.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattbrems/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/mattbrems/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/mattbrems/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Instantiate.\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Fit.\n",
    "X_train = ss.fit_transform(X_train)\n",
    "\n",
    "# Fit.\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Default KNN\n",
    "\n",
    "Below we fit a default `KNeighborsClassifier` to predict `y`. ([Here is the documentation.](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What is the default number of neighbors used in kNN?</summary>\n",
    "    \n",
    "- 5.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate.\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit.\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619047619047619"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate.\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What score is this?</summary>\n",
    "\n",
    "- Accuracy.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.571429\n",
       "1    0.428571\n",
       "Name: females_are_strong_as_hell, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate against the baseline.\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Is selecting k = 5 a good choice? Is it the best choice?</summary>\n",
    "\n",
    "- We don't know!\n",
    "- $k$ is a hyperparameter.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are \"hyperparameters?\"\n",
    "\n",
    "Models often have built-in quantities that we can use to fine-tune our results. \n",
    "- What value of $k$ do we select?\n",
    "- What distance metric do we select?\n",
    "- Do we use LASSO or Ridge regularization?\n",
    "- What value of $\\alpha$ or $C$ do we use?\n",
    "\n",
    "These are quantities our model **cannot** learn. We must decide on these ourselves!\n",
    "\n",
    "> Alternatively, **parameters** are quantities that a model can learn, like the coefficients of a logistic regression model.\n",
    "\n",
    "However, different values for hyperparameters can result in substantially different models. \n",
    "- Let's [visualize fits for different values of $k$](http://scott.fortmann-roe.com/docs/BiasVariance.html) in $k$-nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>We want to find the optimal values for our hyperparameters. How do you think we might do this?</summary>\n",
    "\n",
    "- Try as many different values of hyperparameters as possible and see which ones perform the best on our data.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for the Best Hyperparameters\n",
    "\n",
    "Our default KNN performs quite poorly on the test data. But what if we changed the number of neighbors? The weighting? The distance metric?\n",
    "\n",
    "These are all hyperparameters of the KNN. How would we do this manually? We would need to evaluate on the training data the set of hyperparameters that perform best, and then use this set of hyperparameters to fit the final model and score on the testing set.\n",
    "\n",
    "### Search code for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try 3-NN, 5-NN, 10-NN.\n",
    "neighbors_to_test = [3, 5, 10]\n",
    "\n",
    "# Let's try uniform and distance weightings.\n",
    "weightings_to_test = ['uniform', 'distance']\n",
    "\n",
    "# Let's try Manhattan and Euclidean distances.\n",
    "distance_metrics_to_test = [1, 2] # Remember that p = 1 is Manhattan, p = 2 is Euclidean\n",
    "\n",
    "# Instantiate a dictionary to hold our accuracy scores.\n",
    "accuracies = {}\n",
    "\n",
    "# Loop through number of neighbors.\n",
    "for k in neighbors_to_test:\n",
    "    \n",
    "    # Loop through the weightings.\n",
    "    for w in weightings_to_test:\n",
    "        \n",
    "        # Loop through our distance metrics.\n",
    "        for d in distance_metrics_to_test:\n",
    "            \n",
    "            # Fit a KNN model with that set of hyperparameters.\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, weights=w, p=d)\n",
    "            \n",
    "            # Generate a set of accuracy scores based on 5-fold cross-validation.\n",
    "            cv_accuracies = cross_val_score(knn, X_train, y_train, cv=5)\n",
    "            \n",
    "            # Average the five accuracy scores and store them in the dictionary.\n",
    "            accuracies[(k, w, d)] = np.mean(cv_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the pseudocode above, we would find the key in the dictionary (a hyperparameter set) that has the largest value (mean cross-validated accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Which model should I fit?</summary>\n",
    "    \n",
    "- a 5-nearest neighbors model using distance weighting and the Manhattan distance.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(3, 'uniform', 1): 0.8075641025641026,\n",
       " (3, 'uniform', 2): 0.8383076923076922,\n",
       " (3, 'distance', 1): 0.8152307692307692,\n",
       " (3, 'distance', 2): 0.8379743589743589,\n",
       " (5, 'uniform', 1): 0.7912564102564101,\n",
       " (5, 'uniform', 2): 0.7903076923076922,\n",
       " (5, 'distance', 1): 0.8392820512820511,\n",
       " (5, 'distance', 2): 0.8146410256410256,\n",
       " (10, 'uniform', 1): 0.7265384615384616,\n",
       " (10, 'uniform', 2): 0.7185384615384616,\n",
       " (10, 'distance', 1): 0.8066153846153845,\n",
       " (10, 'distance', 2): 0.7982820512820512}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/grid.jpg)\n",
    "\n",
    "**One method of searching for the optimal set of hyperparameters is called gridsearching.**\n",
    "\n",
    "Gridsearching gets its name from the fact that we are searching over a \"grid\" of parameters. For example, imagine the `n_neighbors` hyperparameters on the x-axis and `distances` on the y-axis, and we need to check the accuracy for all combinations of hyperparameters on the grid.\n",
    "\n",
    "**Gridsearching uses cross-validation internally to evaluate the performance of each set of hyperparameters.** More on this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `GridSearchCV`\n",
    "\n",
    "This would be an annoying process to have to do manually. Luckily sklearn comes with a convenience class for performing gridsearch:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "```\n",
    "\n",
    "The `GridSearchCV` has a handful of important arguments:\n",
    "\n",
    "| Argument | Description |\n",
    "| --- | ---|\n",
    "| **`estimator`** | The sklearn instance of the model to fit on |\n",
    "| **`param_grid`** | A dictionary where keys are hyperparameters for the model and values are lists of values to test |\n",
    "| **`cv`** | The number of internal cross-validation folds to run for each set of hyperparameters |\n",
    "| **`n_jobs`** | How many cores to use on your computer to run the folds (-1 means use all cores) |\n",
    "| **`verbose`** | How much output to display (0 is none, 1 is limited, 2 is printouts for every internal fit) |\n",
    "\n",
    "\n",
    "Below is an example for how one might set up the gridsearch for our KNN:\n",
    "\n",
    "```python\n",
    "knn_parameters = {\n",
    "    'n_neighbors':[3,5,10],\n",
    "    'weights':['uniform','distance'],\n",
    "    'p':[1,2]\n",
    "}\n",
    "\n",
    "knn_gridsearcher = GridSearchCV(KNeighborsClassifier(), knn_parameters, verbose=1)\n",
    "knn_gridsearcher.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Try out the sklearn gridsearch below on the training data.** [You can find the GridSearchCV documentation here.](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of hyperparameters.\n",
    "# The keys MUST match the names of the arguments!\n",
    "knn_params = {\n",
    "    'n_neighbors': range(1, 51, 10),\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our GridSearchCV object.\n",
    "knn_gridsearch = GridSearchCV(KNeighborsClassifier(), # What is the model we want to fit?\n",
    "                              knn_params, # What is the dictionary of hyperparameters?\n",
    "                              cv=5, # What number of folds in CV will we use?\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "/Users/mattbrems/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Fit the GridSearchCV object to the data\n",
    "knn_gridsearch.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the Results of the Grid Search\n",
    "\n",
    "Once the grid search has fit (this can take awhile!) we can pull out a variety of information and useful objects from the gridsearch object, stored as attributes:\n",
    "\n",
    "| Property | Use |\n",
    "| --- | ---|\n",
    "| **`results.param_grid`** | Displays parameters searched over. |\n",
    "| **`results.best_score_`** | Best mean cross-validated score achieved. |\n",
    "| **`results.best_estimator_`** | Reference to model with best score.  Is usable / callable. |\n",
    "| **`results.best_params_`** | The parameters that have been found to perform with the best score. |\n",
    "| **`results.grid_scores_`** | Display score attributes with corresponding parameters. | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.856"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the best score found in the search.\n",
    "\n",
    "knn_gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'manhattan', 'n_neighbors': 1}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the set of hyperparameters that achieved the best score.\n",
    "knn_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can store the best fit model (`best_estimator_`) to a variable, then score it on the test data!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.746031746031746"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the best fit model as best_knn.\n",
    "best_knn = knn_gridsearch.best_estimator_\n",
    "\n",
    "# Evaluate the best fit model on the test data.\n",
    "best_knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's see.... _EVERYTHING!_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattbrems/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/mattbrems/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/mattbrems/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/mattbrems/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/mattbrems/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/mattbrems/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/mattbrems/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_metric</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>1</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 1}</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.030206</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>11</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 11}</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.071464</td>\n",
       "      <td>8</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.831683</td>\n",
       "      <td>0.813973</td>\n",
       "      <td>0.010566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>21</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 21}</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.073506</td>\n",
       "      <td>4</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.801980</td>\n",
       "      <td>0.797972</td>\n",
       "      <td>0.017494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>31</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 31}</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.68</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.110400</td>\n",
       "      <td>3</td>\n",
       "      <td>0.737374</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.821782</td>\n",
       "      <td>0.799831</td>\n",
       "      <td>0.038461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>41</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 41}</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.110121</td>\n",
       "      <td>5</td>\n",
       "      <td>0.747475</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.773911</td>\n",
       "      <td>0.020584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_metric  \\\n",
       "0       0.000878      0.000140         0.001478        0.000557    euclidean   \n",
       "1       0.000551      0.000017         0.000777        0.000046    euclidean   \n",
       "2       0.000552      0.000014         0.000784        0.000002    euclidean   \n",
       "3       0.000560      0.000019         0.000912        0.000128    euclidean   \n",
       "4       0.000567      0.000026         0.000897        0.000072    euclidean   \n",
       "\n",
       "  param_n_neighbors                                      params  \\\n",
       "0                 1   {'metric': 'euclidean', 'n_neighbors': 1}   \n",
       "1                11  {'metric': 'euclidean', 'n_neighbors': 11}   \n",
       "2                21  {'metric': 'euclidean', 'n_neighbors': 21}   \n",
       "3                31  {'metric': 'euclidean', 'n_neighbors': 31}   \n",
       "4                41  {'metric': 'euclidean', 'n_neighbors': 41}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  ...  \\\n",
       "0           0.846154               0.88               0.88  ...   \n",
       "1           0.846154               0.76               0.76  ...   \n",
       "2           0.846154               0.92               0.76  ...   \n",
       "3           0.923077               0.96               0.68  ...   \n",
       "4           0.884615               0.92               0.64  ...   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0            0.848        0.030206                2            1.000000   \n",
       "1            0.744        0.071464                8            0.818182   \n",
       "2            0.800        0.073506                4            0.787879   \n",
       "3            0.816        0.110400                3            0.737374   \n",
       "4            0.784        0.110121                5            0.747475   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0                1.00                1.00                1.00   \n",
       "1                0.81                0.80                0.81   \n",
       "2                0.77                0.81                0.82   \n",
       "3                0.78                0.85                0.81   \n",
       "4                0.75                0.79                0.79   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            1.000000          1.000000         0.000000  \n",
       "1            0.831683          0.813973         0.010566  \n",
       "2            0.801980          0.797972         0.017494  \n",
       "3            0.821782          0.799831         0.038461  \n",
       "4            0.792079          0.773911         0.020584  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(knn_gridsearch.cv_results_).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1161c75c0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gs_df = pd.DataFrame(knn_gridsearch.cv_results_)\n",
    "gs_df = gs_df[gs_df['param_metric'] == 'euclidean']\n",
    "gs_df.plot(x='param_n_neighbors', y='mean_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Word of Caution on Grid Searching\n",
    "\n",
    "`sklearn` models often have many options/hyperparameters with many different possible values. It may be tempting to search over a wide variety of them. In general, this is not wise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Why not?</summary>\n",
    "\n",
    "- Remember that GridSearch searches over **all possible combinations of hyperparameters in the parameter dictionary!**\n",
    "\n",
    "Imagine that we had this as our parameter dictionary:\n",
    "\n",
    "```python\n",
    "parameter_grid = {\n",
    "    'n_neighbors': range(1, 151),\n",
    "    'weights': ['uniform', 'distance', custom_function],\n",
    "    'algorithm': ['ball_tree', 'kd_tree', 'brute', 'auto'],\n",
    "    'leaf_size': range(1, 152),\n",
    "    'metric': ['minkowski', 'euclidean'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "```\n",
    "\n",
    "**How many different combinations will need to be tested?**\n",
    "\n",
    "| Parameter | Number of Chosen Values |\n",
    "| --- | --- |\n",
    "| **n_neighbors** | 150 |\n",
    "| **weights** | 3 |\n",
    "| **algorithm** | 4 |\n",
    "| **leaf_size** | 151 |\n",
    "| **metric** | 2 |\n",
    "| **p** | 2 |\n",
    "| <br>_150 \\* 3 \\* 4 \\* 151 \\* 2 \\* 2 = n combinations_ <br><br>| _1,087,200_ |\n",
    "\n",
    "If we select `cv = 5`, we would fit 1,087,200 models on five folds, meaning we fit 5,436,000 models!\n",
    "\n",
    "If you're not careful, GridSearching can quickly blow up.\n",
    "\n",
    "> **It is extremely important to understand what the hyperparameters do and think critically about what ranges are useful and relevant to your model!**\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An aside: estimators and transformers.\n",
    "`sklearn` has two types of classes: **estimators** and **transformers**. \n",
    "\n",
    "We've seen several examples of each so far.\n",
    "\n",
    "### Scikit-Learn Estimators\n",
    "Estimators are essentially _models_. They fit this format:\n",
    "\n",
    "```python\n",
    "# Instantiate.\n",
    "model = MyCoolModel(params)\n",
    "# Fit.\n",
    "model.fit(X_train, y_train)\n",
    "# Predict.\n",
    "y_pred = model.predict(X_test)\n",
    "```\n",
    "\n",
    "Estimators have a **fit** and **predict** method.\n",
    "\n",
    "### Scikit-Learn Transformers\n",
    "Transformers are not models. They transform your data using similar syntax to estimators. They work like this:\n",
    "\n",
    "```python\n",
    "# Instantiate.\n",
    "trf = MyCoolTransformer(params)\n",
    "# Fit.\n",
    "trf.fit(X_train)\n",
    "# Transform.\n",
    "X_transformed = trf.transform(X_train)\n",
    "```\n",
    "\n",
    "Instead of `fit` and `predict`, they have **fit** and **transform** methods. In fact, since you fit and transform together so often, they have a shortcut:\n",
    "\n",
    "```python\n",
    "trf = MyCoolTransformer(params)\n",
    "X_transformed = trf.fit_transform(X_train)\n",
    "```\n",
    "\n",
    "We've seen a few transformers `StandardScaler()` and `PolynomialFeatures()`. There's also `OneHotEncoder()` for dummy encoding and `LabelEncoder()` for factorizing variables. Later we'll see `PCA()`, which is also a transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is this relevant?\n",
    "\n",
    "Check out the [StandardScaler documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html).\n",
    "\n",
    "Transformers may have hyperparameters as well - **but we can't GridSearch over a transformer**! There's no way for me to get an accuracy (or other) score from just a transformer, since a transformer can't predict!\n",
    "\n",
    "![](./images/grid.jpg)\n",
    "\n",
    "In addition, the acronym ETL, meaning \"extract, transform, load,\" is a very common one in data science. When we gather data from one or more places, there might be **a lot** of preprocessing going on.\n",
    "\n",
    "Oftentimes, we'll want to apply several transformers to a dataset, *then* build a model. \n",
    "- If you do all of these preprocessing steps independently, your code can be messy and it'll be prone to errors!\n",
    "- It can be challenging to consistently recreate this process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "![](./images/pipe.png)\n",
    "\n",
    "Pipelines will allow us to do two things:\n",
    "1. Chain many transformers together before ending in an estimator.\n",
    "2. Allow us to GridSearch over a transformer's hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pipeline\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a StandardScaler + kNN pipeline.\n",
    "pipe = Pipeline([\n",
    "    ('sc', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('sc', StandardScaler(copy=True, with_mean=True, with_std=True)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit.\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619047619047619"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate.\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('sc', StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('knn',\n",
       "   KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "              metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "              weights='uniform'))],\n",
       " 'sc': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'knn': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "            weights='uniform'),\n",
       " 'sc__copy': True,\n",
       " 'sc__with_mean': True,\n",
       " 'sc__with_std': True,\n",
       " 'knn__algorithm': 'auto',\n",
       " 'knn__leaf_size': 30,\n",
       " 'knn__metric': 'minkowski',\n",
       " 'knn__metric_params': None,\n",
       " 'knn__n_jobs': None,\n",
       " 'knn__n_neighbors': 5,\n",
       " 'knn__p': 2,\n",
       " 'knn__weights': 'uniform'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get params - yes, you can GridSearchCV over these!\n",
    "# Notice the naming convention of pipe arguments.\n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate pipeline object.\n",
    "pipe_2 = Pipeline([\n",
    "    ('sc', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary of parameters.\n",
    "pipe_2_params = {'sc__with_mean': [True, False], \n",
    "                 'sc__with_std': [True, False],\n",
    "                 'knn__p': [1, 2], \n",
    "                 'knn__weights': ['uniform', 'distance'],\n",
    "                 'knn__n_neighbors': [3, 5, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our GridSearchCV object.\n",
    "pipe_2_gridsearch = GridSearchCV(pipe_2, # What is the model we want to fit?\n",
    "                                 pipe_2_params, # What is the dictionary of hyperparameters?\n",
    "                                 cv=5, # What number of folds in CV will we use?\n",
    "                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed:    1.0s finished\n",
      "/Users/mattbrems/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Fit the GridSearchCV object to the data.\n",
    "pipe_2_gridsearch.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out best score.\n",
    "pipe_2_gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('sc', StandardScaler(copy=True, with_mean=True, with_std=True)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out best estimator.\n",
    "pipe_2_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best estimator as pipe_2_final.\n",
    "\n",
    "pipe_2_final = pipe_2_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7301587301587301"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the best model on the test data.\n",
    "\n",
    "pipe_2_final.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What would you conclude from this output?</summary>\n",
    "    \n",
    "- Our model is overfit to the data.\n",
    "- GridSearching gets us the best performing model on the training set; we always have to take care to not overfit!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## (BONUS) RandomizedSearchCV + Visualizing Results\n",
    "\n",
    "When you're exploring a particularly high number of different parameters, it can be advantageous to do a randomized search instead of a GridSearch.\n",
    "\n",
    "`from sklearn.model_selection import RandomizedSearchCV`\n",
    "\n",
    "A good blog post on GridSearch, RandomizedSearch, and visualizing the outputs of these methods [can be found here](https://towardsdatascience.com/using-3d-visualizations-to-tune-hyperparameters-of-ml-models-with-python-ba2885eab2e9)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
